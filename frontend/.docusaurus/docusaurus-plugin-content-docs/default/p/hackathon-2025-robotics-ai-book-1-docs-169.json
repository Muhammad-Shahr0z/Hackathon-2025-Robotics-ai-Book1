{"version":{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"link","href":"/Hackathon-2025-Robotics-ai-Book1/docs/","label":"Introduction","docId":"introduction","unlisted":false},{"type":"category","label":"Module 1: The Robotic Nervous System (ROS 2)","collapsed":false,"collapsible":true,"items":[{"type":"link","href":"/Hackathon-2025-Robotics-ai-Book1/docs/module-1/chapter-1","label":"Chapter 1: Introduction to Embodied AI and Robotics","docId":"module-1/chapter-1","unlisted":false},{"type":"link","href":"/Hackathon-2025-Robotics-ai-Book1/docs/module-1/chapter-2","label":"Chapter 2: ROS 2 Fundamentals: Nodes, Topics, and Services","docId":"module-1/chapter-2","unlisted":false},{"type":"link","href":"/Hackathon-2025-Robotics-ai-Book1/docs/module-1/chapter-3","label":"Chapter 3: ROS 2 Tools: RViz, Gazebo, and the CLI","docId":"module-1/chapter-3","unlisted":false}],"href":"/Hackathon-2025-Robotics-ai-Book1/docs/module-1/"},{"type":"category","label":"Module 2: The Digital Twin (Gazebo & Unity)","collapsed":true,"items":[{"type":"link","href":"/Hackathon-2025-Robotics-ai-Book1/docs/module-2/chapter-4","label":"Chapter 4: Camera Systems and Image Processing in ROS 2","docId":"module-2/chapter-4","unlisted":false},{"type":"link","href":"/Hackathon-2025-Robotics-ai-Book1/docs/module-2/chapter-5","label":"Chapter 5: Lidar and Depth Sensing: Building Point Clouds","docId":"module-2/chapter-5","unlisted":false},{"type":"link","href":"/Hackathon-2025-Robotics-ai-Book1/docs/module-2/chapter-6","label":"Chapter 6: Sensor Fusion: Combining Data for Robust Perception","docId":"module-2/chapter-6","unlisted":false}],"collapsible":true,"href":"/Hackathon-2025-Robotics-ai-Book1/docs/module-2/"},{"type":"category","label":"Module 3: Motion, Control, and Navigation","collapsed":true,"items":[{"type":"link","href":"/Hackathon-2025-Robotics-ai-Book1/docs/module-3/chapter-7","label":"Chapter 7: Inverse Kinematics for Humanoid Arms","docId":"module-3/chapter-7","unlisted":false},{"type":"link","href":"/Hackathon-2025-Robotics-ai-Book1/docs/module-3/chapter-8","label":"Chapter 8: Bipedal Locomotion: Walking and Balance","docId":"module-3/chapter-8","unlisted":false},{"type":"link","href":"/Hackathon-2025-Robotics-ai-Book1/docs/module-3/chapter-9","label":"Chapter 9: Navigation Stack: From A to B Autonomously","docId":"module-3/chapter-9","unlisted":false}],"collapsible":true,"href":"/Hackathon-2025-Robotics-ai-Book1/docs/module-3/"},{"type":"category","label":"Module 4: Advanced Topics and Real-World Deployment","collapsed":true,"items":[{"type":"link","href":"/Hackathon-2025-Robotics-ai-Book1/docs/module-4/chapter-10","label":"Chapter 10: NVIDIA Isaac Sim and Omniverse","docId":"module-4/chapter-10","unlisted":false},{"type":"link","href":"/Hackathon-2025-Robotics-ai-Book1/docs/module-4/chapter-11","label":"Chapter 11: Vision-Language-Action (VLA) Models","docId":"module-4/chapter-11","unlisted":false},{"type":"link","href":"/Hackathon-2025-Robotics-ai-Book1/docs/module-4/chapter-12","label":"Chapter 12: Deploying to Real Hardware","docId":"module-4/chapter-12","unlisted":false}],"collapsible":true,"href":"/Hackathon-2025-Robotics-ai-Book1/docs/module-4/"},{"type":"category","label":"Module 5: Capstone Projects","collapsed":true,"items":[{"type":"link","href":"/Hackathon-2025-Robotics-ai-Book1/docs/module-5/capstone","label":"Capstone Project: The Autonomous Humanoid","docId":"module-5/capstone","unlisted":false}],"collapsible":true,"href":"/Hackathon-2025-Robotics-ai-Book1/docs/module-5/"}]},"docs":{"introduction":{"id":"introduction","title":"Physical AI & Humanoid Robotics","description":"Focus and Theme","sidebar":"tutorialSidebar"},"module-1/chapter-1":{"id":"module-1/chapter-1","title":"Chapter 1: Introduction to Embodied AI and Robotics","description":"Description: Explore the fundamental concepts of embodied intelligence and the role of robotics in the physical world.","sidebar":"tutorialSidebar"},"module-1/chapter-2":{"id":"module-1/chapter-2","title":"Chapter 2: ROS 2 Fundamentals - Nodes, Topics, and Services","description":"Description: Master the core architecture of ROS 2, the middleware that powers modern robotics.","sidebar":"tutorialSidebar"},"module-1/chapter-3":{"id":"module-1/chapter-3","title":"Chapter 3: ROS 2 Tools - RViz, Gazebo, and the CLI","description":"Description: Learn the essential tools for visualizing, simulating, and debugging robot systems.","sidebar":"tutorialSidebar"},"module-1/index":{"id":"module-1/index","title":"Module 1: The Robotic Nervous System (ROS 2)","description":"Focus: Middleware for robot control.","sidebar":"tutorialSidebar"},"module-2/chapter-4":{"id":"module-2/chapter-4","title":"Chapter 4: Camera Systems and Image Processing in ROS 2","description":"Description: Process visual data from cameras to enable robot perception.","sidebar":"tutorialSidebar"},"module-2/chapter-5":{"id":"module-2/chapter-5","title":"Chapter 5: Lidar and Depth Sensing - Building Point Clouds","description":"Description: Use Lidar and depth cameras to create 3D representations of the environment.","sidebar":"tutorialSidebar"},"module-2/chapter-6":{"id":"module-2/chapter-6","title":"Chapter 6: Sensor Fusion - Combining Data for Robust Perception","description":"Description: Integrate multiple sensors to create a comprehensive understanding of the environment.","sidebar":"tutorialSidebar"},"module-2/index":{"id":"module-2/index","title":"Module 2: The Digital Twin (Gazebo & Unity)","description":"Focus: Physics simulation and environment building.","sidebar":"tutorialSidebar"},"module-3/chapter-7":{"id":"module-3/chapter-7","title":"Chapter 7: Inverse Kinematics for Humanoid Arms","description":"Description: Calculate joint angles to achieve desired end-effector positions.","sidebar":"tutorialSidebar"},"module-3/chapter-8":{"id":"module-3/chapter-8","title":"Chapter 8: Bipedal Locomotion - Walking and Balance","description":"Description: Implement walking gaits and balance control for humanoid robots.","sidebar":"tutorialSidebar"},"module-3/chapter-9":{"id":"module-3/chapter-9","title":"Chapter 9: Navigation Stack - From A to B Autonomously","description":"Description: Enable robots to navigate autonomously using the Nav2 stack.","sidebar":"tutorialSidebar"},"module-3/index":{"id":"module-3/index","title":"Module 3: Motion, Control, and Navigation","description":"Focus: Kinematics, locomotion, and autonomous navigation.","sidebar":"tutorialSidebar"},"module-4/chapter-10":{"id":"module-4/chapter-10","title":"Chapter 10: NVIDIA Isaac Sim and Omniverse","description":"Description: Leverage photorealistic simulation for training and testing.","sidebar":"tutorialSidebar"},"module-4/chapter-11":{"id":"module-4/chapter-11","title":"Chapter 11: Vision-Language-Action (VLA) Models","description":"Description: Integrate large language models with robot control.","sidebar":"tutorialSidebar"},"module-4/chapter-12":{"id":"module-4/chapter-12","title":"Chapter 12: Deploying to Real Hardware","description":"Description: Transfer your simulated systems to physical robots.","sidebar":"tutorialSidebar"},"module-4/index":{"id":"module-4/index","title":"Module 4: Advanced Topics and Real-World Deployment","description":"Focus: NVIDIA Isaac, VLA models, and hardware deployment.","sidebar":"tutorialSidebar"},"module-5/capstone":{"id":"module-5/capstone","title":"Capstone Project: The Autonomous Humanoid","description":"Description: Build a complete autonomous humanoid system that integrates perception, planning, and control.","sidebar":"tutorialSidebar"},"module-5/index":{"id":"module-5/index","title":"Module 5: Capstone Projects","description":"Focus: Building complete autonomous systems.","sidebar":"tutorialSidebar"}}}}